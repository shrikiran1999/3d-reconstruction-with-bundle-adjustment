{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e60109dd740a1c92feb05d30890eaf1a",
     "grade": false,
     "grade_id": "cell-c4ab9a740c51dfd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"images/course.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "638f6a5696206b7c42fd1c94bc5ea241",
     "grade": false,
     "grade_id": "cell-3c6401138ee3087d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 16720 (B)  3D Reconstruction - Assignment 5 - q2\n",
    "    Instructor: Kris                          TAs: Arka, Jinkun, Rawal, Rohan, Sheng-Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f3c89e7b4bf37baccf8215081777edd",
     "grade": false,
     "grade_id": "cell-951f7cf42448155b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions for this assignment. DO NOT MODIFY!!!\n",
    "\"\"\"\n",
    "Helper functions.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy\n",
    "import nbimporter\n",
    "from q1 import eightpoint, camera2, _epipoles, toHomogenous\n",
    "\n",
    "def epipolarMatchGUI(I1, I2, F):\n",
    "    matplotlib.use('TkAgg')\n",
    "    e1, e2 = _epipoles(F)\n",
    "\n",
    "    sy, sx, _ = I2.shape\n",
    "\n",
    "    f, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 9))\n",
    "    ax1.imshow(I1)\n",
    "    ax1.set_title('Select a point in this image')\n",
    "    ax1.set_axis_off()\n",
    "    ax2.imshow(I2)\n",
    "    ax2.set_title('Verify that the corresponding point \\n is on the epipolar line in this image')\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    while True:\n",
    "        plt.sca(ax1)\n",
    "        x, y = plt.ginput(1, mouse_stop=2)[0]\n",
    "\n",
    "        xc = int(x)\n",
    "        yc = int(y)\n",
    "        v = np.array([xc, yc, 1])\n",
    "        l = F.dot(v)\n",
    "        s = np.sqrt(l[0]**2+l[1]**2)\n",
    "\n",
    "        if s==0:\n",
    "            error('Zero line vector in displayEpipolar')\n",
    "\n",
    "        l = l/s;\n",
    "\n",
    "        if l[0] != 0:\n",
    "            ye = sy-1\n",
    "            ys = 0\n",
    "            xe = -(l[1] * ye + l[2])/l[0]\n",
    "            xs = -(l[1] * ys + l[2])/l[0]\n",
    "        else:\n",
    "            xe = sx-1\n",
    "            xs = 0\n",
    "            ye = -(l[0] * xe + l[2])/l[1]\n",
    "            ys = -(l[0] * xs + l[2])/l[1]\n",
    "\n",
    "        # plt.plot(x,y, '*', 'MarkerSize', 6, 'LineWidth', 2);\n",
    "        ax1.plot(x, y, '*', MarkerSize=6, linewidth=2)\n",
    "        ax2.plot([xs, xe], [ys, ye], linewidth=2)\n",
    "\n",
    "        # draw points\n",
    "        x2, y2 = epipolarCorrespondence(I1, I2, F, xc, yc)\n",
    "        ax2.plot(x2, y2, 'ro', MarkerSize=8, linewidth=2)\n",
    "        plt.draw()\n",
    "\n",
    "def plot_3D(P):\n",
    "    matplotlib.use('TkAgg')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(P[:,0], P[:,1], P[:,2])\n",
    "    while True:\n",
    "        x, y = plt.ginput(1, mouse_stop=2)[0]\n",
    "        plt.draw()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef2fb02cee64bf9716a4cf20a24ec3e6",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2: Metric Reconstruction\n",
    "You will compute the camera matrices and triangulate the 2D points to obtain the 3D scene structure. To obtain the Euclidean scene structure, first convert the fundamental matrix $\\textbf{F}$ to an essential matrix $\\textbf{E}$. Examine the lecture notes and the textbook to find out how to do this when the internal camera calibration matrices $\\textbf{K}_1$ and $\\textbf{K}_2$ are known; these are provided in `data/intrinsics.npz`.\n",
    "\n",
    "### Q2.1: Essential Matrix (5 pt implementation)\n",
    "Write a function to compute the essential matrix $\\textbf{E}$ given $\\textbf{F}$, $\\textbf{K}_1$ and $\\textbf{K}_2$ with the signature:\n",
    "\n",
    "```\n",
    "E = essentialMatrix(F, K1, K2)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac09d93d25047c98352b2ee7d86bf1af",
     "grade": false,
     "grade_id": "cell-75539a0c38616db4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def essentialMatrix(F, K1, K2):\n",
    "    '''\n",
    "    Q1.1: Compute the essential matrix E given the fundamental matrix and camera intrinsics\n",
    "        Input:  F, fundamental matrix\n",
    "                K1, internal camera calibration matrix of camera 1\n",
    "                K2, internal camera calibration matrix of camera 2\n",
    "        Output: E, the essential matrix\n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    # from page 228 Forsyth and Ponce\n",
    "    E = K2.T @ F @ K1\n",
    "    # raise NotImplementedError()\n",
    "    return E\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d525d660703f30c72575d4d386aa455f",
     "grade": false,
     "grade_id": "cell-a3a93f3bfd0a89f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000107\n",
      "         Iterations: 8\n",
      "         Function evaluations: 894\n",
      "[[  -0.5069   68.6543 -371.9615]\n",
      " [  29.7107   -1.5472    9.6823]\n",
      " [ 372.9911    2.9855    0.1504]]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the essential matrix\n",
    "np.set_printoptions(precision=4, suppress=1)\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1 = plt.imread('data/im1.png')\n",
    "im2 = plt.imread('data/im2.png')\n",
    "\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "E = essentialMatrix(F, K1, K2)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cd36d551bf89de67c9b8f5d8b61703b",
     "grade": true,
     "grade_id": "q2_1_a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000107\n",
      "         Iterations: 8\n",
      "         Function evaluations: 894\n"
     ]
    }
   ],
   "source": [
    "# Simple Tests to verify your implmentation:\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "E = essentialMatrix(F, K1, K2)\n",
    "assert(np.linalg.matrix_rank(E) == 2)\n",
    "\n",
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Triangulation and find M2 (5 pt writeup, 20 pt implementation)\n",
    "Given an essential matrix, it is possible to retrieve the projective camera matrices $\\textbf{M}_1$ and $\\textbf{M}_2$ from it.  Assuming $\\textbf{M}_1$ is fixed at $[\\textbf{I},0]$, $\\textbf{M}_2$ can be retrieved up to a scale and four-fold rotation ambiguity. For details on recovering $\\textbf{M}_2$, see section 7.2 in Szeliski. We have provided you with the function `camera2` to recover as the four possible $\\textbf{M}_2$ matrices given $\\textbf{E}$.\n",
    "\n",
    "**Note:** The $\\textbf{M}_1$ and $\\textbf{M}_2$ here are projection matrices of the form:\n",
    "$\\textbf{M}_1 = \\begin{bmatrix}\n",
    "\\textbf{I} | 0\n",
    "\\end{bmatrix} $ and $\\textbf{M}_2 = \\begin{bmatrix}\n",
    "\\textbf{R} | \\textbf{t}\n",
    "\\end{bmatrix} $.\n",
    "\n",
    "Using the above, write a function to triangulate a set of 2D coordinates in the image to a set of 3D\n",
    "points with the signature:\n",
    "```\n",
    "    [w, err] = triangulate(C1, pts1, C2, pts2)\n",
    "```\n",
    "where `pts1` and `pts2` are the $N \\times 2$ matrices with the 2D image coordinates and `w` is an $N \\times 3$ matrix with the corresponding 3D points per row.  `C1` and `C2` are the $3 \\times 4$ camera matrices. Remember that you will need to multiply the given intrinsics matrices with your solution for the canonical camera matrices to obtain the final camera matrices. Various methods exist for triangulation - probably the most familiar for you is based on least squares (see Szeliski Chapter 7 if you want to learn about other methods):\n",
    "\n",
    "For each point $i$, we want to solve for 3D coordinates $\\textbf{w}_i = \\begin{bmatrix}x_i, y_i, z_i\\end{bmatrix}^T$, such that when they are projected back to the two images, they are close to the original 2D points. To project the 3D coordinates back to 2D images, we first write $\\textbf{w}_i$ in homogeneous coordinates, and compute $\\mathbf{C}_1 \\tilde{\\textbf{w}_i}$ and $\\mathbf{C}_2 \\tilde{\\textbf{w}_i}$ to obtain the 2D homogeneous coordinates projected to camera $1$ and camera $2$, respectively.\n",
    "\n",
    "For each point $i$, we can write this problem in the following form:\n",
    "\\begin{align}\n",
    "\\mathbf{A}_i w_i = 0\n",
    "\\end{align}\n",
    "where $\\mathbf{A}_i$ is a $4\\times 4$ matrix, and $\\tilde{\\textbf{w}_i}$ is a $4\\times 1$ vector of the 3D coordinates in the homogeneous form. Then, you can obtain the homogeneous least-squares solution (discussed in class) to solve for each $\\textbf{w}_i$.\n",
    "\n",
    "Once you have implemented triangulation, you can check the performance by looking at the reprojection error:  $$ \\texttt{err} = \\sum_i ||\\textbf{x}_{1i} - \\widehat{\\textbf{x}_{1i}}||^2 + ||\\textbf{x}_{2i} - \\widehat{\\textbf{x}_{2i}}||^2$$\n",
    "where $\\widehat{\\textbf{x}_{1i}} = Proj(\\mathbf{C}_1, \\textbf{w}_i)$ and $\\widehat{\\textbf{x}_{2i}} = Proj(\\mathbf{C}_2, \\textbf{w}_i)$.\n",
    "\n",
    "\n",
    "**Note:** `C1` and `C2` here are projection matrices of the form:\n",
    "$\\mathbf{C}_1 = \\mathbf{K}_1\\mathbf{M}_1 = \\mathbf{K}_1 \\begin{bmatrix}\n",
    "\\textbf{I} | 0\n",
    "\\end{bmatrix} $ and $\\mathbf{C}_2 =  \\mathbf{K}_2\\mathbf{M}_2 = \\mathbf{K}_2 \\begin{bmatrix}\n",
    "\\textbf{R} | \\textbf{t}\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "Write a function, \n",
    "```\n",
    "    [M2, C2, P] = findM2()\n",
    "```\n",
    "to load the correspondences and use triangulation to find the M2, C2, and P that minimize the reprojection error. \n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: Write down the expression for the matrix $\\mathbf{A}_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdb9dd4c5b8428762b8d535d0d4b2f5b",
     "grade": false,
     "grade_id": "cell-af5ab5f8a3142145",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def triangulate(C1, pts1, C2, pts2):\n",
    "    '''\n",
    "    Q2.2: Triangulate a set of 2D coordinates in the image to a set of 3D points.\n",
    "        Input:  C1, the 3x4 camera matrix\n",
    "                pts1, the Nx2 matrix with the 2D image coordinates per row\n",
    "                C2, the 3x4 camera matrix\n",
    "                pts2, the Nx2 matrix with the 2D image coordinates per row\n",
    "        Output: P, the Nx3 matrix with the corresponding 3D points per row\n",
    "                err, the reprojection error.\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) For every input point, form A using the corresponding points from pts1 & pts2 and C1 & C2\n",
    "    (2) Solve for the least square solution using np.linalg.svd\n",
    "    (3) Calculate the reprojection error using the calculated 3D points and C1 & C2 (do not forget to convert from \n",
    "        homogeneous coordinates to non-homogeneous ones)\n",
    "    (4) Keep track of the 3D points and projection error, and continue to next point \n",
    "    (5) You do not need to follow the exact procedure above. \n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    N = pts1.shape[0]\n",
    "    C11, C12, C13 = C1[0,:], C1[1,:], C1[2,:]\n",
    "    C21, C22, C23 = C2[0,:], C2[1,:], C2[2,:] \n",
    "    err = 0\n",
    "    P = []\n",
    "    for i in range(N):\n",
    "        (x, y) = pts1[i,:]\n",
    "        (x_, y_) = pts2[i,:]\n",
    "        A = np.array([y*(C13) - C12,\n",
    "                      C11 - x*(C13),\n",
    "                      y_*(C23) - C22,\n",
    "                      C21 - x_*(C23)])\n",
    "    \n",
    "        assert A.shape==(4,4), 'A dims wrong'\n",
    "        U, S, VT = np.linalg.svd(A)\n",
    "        p = VT[-1,:] # last row of VT => last column of V (4,)\n",
    "        p = p/p[-1] # [X,Y,Z,1] (wi in homogeneous coordinates)\n",
    "        wi = p[:-1] # [X,Y,Z]\n",
    "        P.append(wi)\n",
    "        \n",
    "        X1i_cap = C1@(p.T)\n",
    "        X1i_cap = X1i_cap/X1i_cap[-1]\n",
    "        X1i_cap = X1i_cap[:-1]\n",
    "\n",
    "        X2i_cap = C2@(p.T)\n",
    "        X2i_cap = X2i_cap/X2i_cap[-1]\n",
    "        X2i_cap = X2i_cap[:-1]\n",
    "        # calculating reprojection error\n",
    "        err += np.linalg.norm(np.array([x,y]).T-X1i_cap)**2 + np.linalg.norm(np.array([x_,y_]).T-X2i_cap)**2\n",
    "\n",
    "    print(A)\n",
    "        \n",
    "    P = np.array(P)\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    return P, err\n",
    "    \n",
    "\n",
    "def find_M2(F, pts1, pts2, intrinsics):\n",
    "    '''\n",
    "    Q2.2: Function to find the camera2's projective matrix given correspondences\n",
    "        Input:  F, the pre-computed fundamental matrix\n",
    "                pts1, the Nx2 matrix with the 2D image coordinates per row\n",
    "                pts2, the Nx2 matrix with the 2D image coordinates per row\n",
    "                intrinsics, the intrinsics of the cameras, load from the .npz file\n",
    "        Output: [M2, C2, P] the computed M2 (3x4) camera projective matrix, C2 (3x4) K2 * M2, and the 3D points P (Nx3)\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) Loop through the 'M2s' and use triangulate to calculate the 3D points and projection error. Keep track \n",
    "        of the projection error through best_error and retain the best one. \n",
    "    (2) Remember to take a look at camera2 to see how to correctly reterive the M2 matrix from 'M2s'. \n",
    "\n",
    "    '''\n",
    "    K1 = intrinsics[\"K1\"]\n",
    "    K2 = intrinsics[\"K2\"]\n",
    "    E = essentialMatrix(F, K1, K2)\n",
    "    M1 = np.hstack((np.identity(3), np.zeros(3)[:,np.newaxis]))\n",
    "    C1 = K1.dot(M1)\n",
    "    M2s = camera2(E) # 4 possible M2 matrices (3, 4, 4)\n",
    "    best_error = np.finfo('float').max # largest representable floating point number\n",
    "    M2 = np.zeros_like(M2s[:,:,0])\n",
    "    C2 = np.zeros_like(C1)\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    n_M2s = M2s.shape[2]\n",
    "    P_best = None\n",
    "    for i in range(n_M2s):\n",
    "        M2i = M2s[:,:,i]\n",
    "        C2i = K2.dot(M2i)\n",
    "        P, err = triangulate(C1, pts1, C2i, pts2)\n",
    "        # print(err)\n",
    "        if err<best_error and not np.any(P[:,2]<0, axis=0):\n",
    "            best_error = err\n",
    "            M2 = M2i\n",
    "            C2 = C2i\n",
    "            P_best = P\n",
    "\n",
    "    P = P_best\n",
    "    # raise NotImplementedError()\n",
    "    print(f\"Best Error {best_error}\")\n",
    "    return M2, C2, P\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b4f00e6f91dfec1202922246eb0dc3",
     "grade": false,
     "grade_id": "cell-e702426864c5ae3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000107\n",
      "         Iterations: 8\n",
      "         Function evaluations: 894\n",
      "[[    0.     -1525.9      -87.87       0.    ]\n",
      " [ 1520.4        0.        66.32       0.    ]\n",
      " [  -27.1612 -1527.0144   -65.5751  1518.5853]\n",
      " [-1520.2631    33.8465   -62.757    -34.0881]]\n",
      "[[    0.     -1525.9      -87.87       0.    ]\n",
      " [ 1520.4        0.        66.32       0.    ]\n",
      " [  -27.1612 -1527.0144   -65.5751 -1518.5853]\n",
      " [-1520.2631    33.8465   -62.757     34.0881]]\n",
      "[[    0.     -1525.9      -87.87       0.    ]\n",
      " [ 1520.4        0.        66.32       0.    ]\n",
      " [   51.2048 -1449.186   -483.7859  1518.5853]\n",
      " [ 1519.7233    32.9612    75.0886   -34.0881]]\n",
      "[[    0.     -1525.9      -87.87       0.    ]\n",
      " [ 1520.4        0.        66.32       0.    ]\n",
      " [   51.2048 -1449.186   -483.7859 -1518.5853]\n",
      " [ 1519.7233    32.9612    75.0886    34.0881]]\n",
      "Best Error 351.8979672663218\n",
      "M2: [[ 0.9994  0.0333  0.006  -0.026 ]\n",
      " [-0.0337  0.9653  0.2589 -1.    ]\n",
      " [ 0.0028 -0.2589  0.9659  0.0796]]\n",
      "C2 [[ 1520.3898   -27.6331   301.1061   -15.4571]\n",
      " [  -50.7634  1409.0488   633.4983 -1506.2442]\n",
      " [    0.0028    -0.2589     0.9659     0.0796]]\n"
     ]
    }
   ],
   "source": [
    "# Running the find_M2 funciton:\n",
    "np.set_printoptions(precision=4, suppress=1)\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "\n",
    "F = eightpoint(pts1, pts2, M = np.max([*im1.shape, *im2.shape]))\n",
    "M2, C2, P = find_M2(F, pts1, pts2, intrinsics)\n",
    "print(f\"M2: {M2}\")\n",
    "print(f\"C2 {C2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cbfe145e9612245e8a7713c9160bf3b",
     "grade": true,
     "grade_id": "q2_2_a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.     -1525.9      -87.87       0.    ]\n",
      " [ 1520.4        0.        66.32       0.    ]\n",
      " [   51.2048 -1449.186   -483.7859  1518.5853]\n",
      " [ 1519.7233    32.9612    75.0886   -34.0881]]\n",
      "error: 351.8979672663218\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Simple Tests to verify your implmentation:\n",
    "M1 = np.hstack((np.identity(3), np.zeros(3)[:,np.newaxis]))\n",
    "C1 = K1.dot(M1)\n",
    "C2 = K2.dot(M2)\n",
    "P_test, err = triangulate(C1, pts1, C2, pts2)\n",
    "print('error:', err)\n",
    "try:\n",
    "    assert(err < 500)\n",
    "    print('Test passed!')\n",
    "except:\n",
    "    raise AssertionError('Test Failed: error greater than 500!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61222c3806992202593591f185dd999a",
     "grade": true,
     "grade_id": "q2_2_b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 Epipolar Correspondence (5 pt writeup, 10 pt implementation)\n",
    "\n",
    "You will now create a 3D visualization of the temple images. By treating our\n",
    "two images as a stereo-pair, we can triangulate corresponding points in each\n",
    "image, and render their 3D locations.\n",
    "\n",
    "\n",
    "\n",
    "Implement a function with the\n",
    "signature:\n",
    "```\n",
    "    [x2, y2] = epipolarCorrespondence(im1, im2, F, x1, y1)\n",
    "```\n",
    "\n",
    "This function takes in the $x$ and $y$ coordinates of a pixel on `im1` and your fundamental matrix $\\textbf{F}$, and returns the coordinates of the pixel on `im2` which correspond to the input point. The match is obtained by computing the similarity of a small window around the $(x_1, y_1)$ coordinates in `im1` to various windows around possible matches in the `im2` and returning the closest.\n",
    "\n",
    "Instead of searching for the matching point at every possible location in `im2`, we can use $\\textbf{F}$ and simply search over the set of pixels that lie along the epipolar line (recall that the epipolar line passes through a single\n",
    "point in `im2`  which corresponds to the point $(x_1, y_1)$ in `im1`!.\n",
    "\n",
    "There are various possible ways to compute the window similarity. For this assignment, simple methods such as the Euclidean or Manhattan distances between the intensity of the pixels should suffice.  See Szeliski Chapter 11, on stereo matching, for a brief overview of these and other methods.\n",
    "\n",
    "\n",
    "**Implementation hints:**\n",
    "- Experiments with various window sizes.\n",
    "- It may help to use a Gaussian weighting of the window, so that the center\n",
    "  has greater influence than the periphery.\n",
    "- Since the two images only differ by a small amount, it might be beneficial to consider matches for which the distance from $(x_1, y_1)$ to $(x_2, y_2)$ is small.\n",
    "\n",
    "To help you test your `epipolarCorrespondence`, we have included a helper function `epipolarMatchGUI`, which takes in two images the fundamental matrix.\n",
    "\n",
    "This GUI allows you to click on a point in `im1`, and will use your function to display the corresponding point in `im2`. See:\n",
    "\n",
    "<img align=\"center\" src=\"images/q3gui_disp_arun.png\" width=\"800\">\n",
    "\n",
    "It's not necessary for your matcher to get **every** possible point right, but it should get easy points (such as those with distinctive corner-like windows).\n",
    "\n",
    "It should also be good enough to render an intelligible representation in the next question.\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up, include a screenshot of `epipolarMatchGUI`\n",
    "with some detected correspondences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec0941499b7bf0932b473b2a9b03a60b",
     "grade": false,
     "grade_id": "cell-5675d5028163b272",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "\n",
    "def epipolarCorrespondence(im1, im2, F, x1, y1):\n",
    "    '''\n",
    "    Q2.3 3D visualization of the temple images.\n",
    "        Input:  im1, the first image\n",
    "                im2, the second image\n",
    "                F, the fundamental matrix\n",
    "                x1, x-coordinates of a pixel on im1\n",
    "                y1, y-coordinates of a pixel on im1\n",
    "        Output: x2, x-coordinates of the pixel on im2\n",
    "                y2, y-coordinates of the pixel on im2\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) Given input [x1, x2], use the fundamental matrix to recover the corresponding epipolar line on image2\n",
    "    (2) Search along this line to check nearby pixel intensity (you can define a search window) to \n",
    "        find the best matches\n",
    "    (3) Use guassian weighting to weight the pixel simlairty\n",
    "    \n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    e1, e2 = _epipoles(F)\n",
    "    sy, sx, _ = im2.shape\n",
    "\n",
    "    xc = x1\n",
    "    yc = y1\n",
    "    v = np.array([xc, yc, 1])\n",
    "    l = F.dot(v)\n",
    "    s = np.sqrt(l[0]**2+l[1]**2)\n",
    "\n",
    "    if s==0:\n",
    "        error('Zero line vector in displayEpipolar')\n",
    "\n",
    "    l = l/s\n",
    "\n",
    "    if l[0] != 0:\n",
    "        ye = sy-1\n",
    "        ys = 0\n",
    "        xe = -(l[1] * ye + l[2])/l[0]\n",
    "        xs = -(l[1] * ys + l[2])/l[0]\n",
    "    else:\n",
    "        xe = sx-1\n",
    "        xs = 0\n",
    "        ye = -(l[0] * xe + l[2])/l[1]\n",
    "        ys = -(l[0] * xs + l[2])/l[1]\n",
    "\n",
    "    # points_along_el = []\n",
    "    # for x in range(np.ceil(xs).astype(int), np.floor(xe).astype(int)):\n",
    "    #     y = -(l[0] * x + l[2])/l[1]\n",
    "    #     y = int(y)\n",
    "    #     pt = [x,y]\n",
    "    #     points_along_el.append(pt)\n",
    "    N = max( (ye-ys), (xe-xs) )\n",
    "    x2_list = np.linspace(xs, xe, N)\n",
    "    y2_list = np.linspace(ys, ye, N)\n",
    "\n",
    "    # x2_list = np.rint(x2_list).astype(int)\n",
    "    # y2_list = np.rint(y2_list).astype(int)\n",
    "    x2_list = np.array(x2_list).astype(int)\n",
    "    y2_list = np.array(y2_list).astype(int)\n",
    "\n",
    "    \n",
    "    k = 51 # window size (k,k)\n",
    "    sigma = 31 # std dev in gaussian weighting\n",
    "    assert k%2 !=0, 'window size should be odd'\n",
    "    assert x1 >= k//2 and y1 >= k//2 and x1 + k//2 <= sx-1 and y1 + k//2 <= sy-1, 'point too close to corner or is out of bounds'\n",
    "\n",
    "    patch_1 = im1[y1 - k//2: y1 - k//2 + k, x1 - k//2: x1 - k//2 + k, :]\n",
    "    patch_1 = np.asarray(patch_1)\n",
    "\n",
    "    # gauss_filter = create_gauss_filter(k, sigma)\n",
    "    # kernel = makeGaussianFiler(k, sigma)\n",
    "    # kernel /= np.sum(kernel)\n",
    "    # kernel = np.asarray(kernel)\n",
    "    # kernel = np.dstack( ( kernel, kernel, kernel  )  )\n",
    "    dist_min = np.inf\n",
    "    best_pt = None\n",
    "    # for pt in points_along_el:\n",
    "    for pt in list(zip(x2_list, y2_list)):\n",
    "\n",
    "        x2,y2 = pt\n",
    "        if x2 >= k//2 and y2 >= k//2 and x2 + k//2 <= sx-1 and y2 + k//2 <= sy-1:\n",
    "            patch_2 = im2[y2 - k//2: y2 - k//2 + k, x2 - k//2: x2 - k//2 + k, :]\n",
    "            patch_2 = np.asarray(patch_2)\n",
    "            diff = patch_1-patch_2\n",
    "            dist = np.linalg.norm(diff)\n",
    "\n",
    "            \n",
    "            if dist < dist_min:\n",
    "                best_pt = pt\n",
    "                dist_min = dist\n",
    "\n",
    "    x2,y2 = best_pt\n",
    "\n",
    "    return x2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a879b356da74a3d7a663b0d3978d1e2b",
     "grade": false,
     "grade_id": "cell-8dc6e1c9f5d0af41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000107\n",
      "         Iterations: 8\n",
      "         Function evaluations: 894\n"
     ]
    }
   ],
   "source": [
    "# Visualization:\n",
    "np.set_printoptions(precision=4, suppress=1)\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "# epipolarMatchGUI(im1, im2, F) ## uncomment to visualize, comment out before submitting to gradescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4043472603f8b65fd08fba61e6c607d7",
     "grade": true,
     "grade_id": "q2_3_a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000107\n",
      "         Iterations: 8\n",
      "         Function evaluations: 894\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Simple Tests to verify your implmentation:\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "x2, y2 = epipolarCorrespondence(im1, im2, F, 119, 217)\n",
    "\n",
    "try:\n",
    "    assert(np.linalg.norm(np.array([x2, y2]) - np.array([118, 181])) < 10)\n",
    "    print('Test passed!')\n",
    "except:\n",
    "    raise AssertionError('Test Failed: error greater than 10!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e4930df209e0a35044969dd369bc9b9",
     "grade": true,
     "grade_id": "q2_3_b",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2e7990f2939e59119f656de861837b3",
     "grade": false,
     "grade_id": "cell-83938fccb883a2d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.4 3D Visualization (3pt writeup, 7 pt implementation) \n",
    "\n",
    "Included in this homework  is a file data/templeCoords.npz which contains 288 hand-selected points from `im1` saved in the variables `x1` and `y1`.\n",
    "\n",
    "Now, we can determine the 3D location of these point correspondences using the `triangulate` function. These 3D point locations can then plotted using the `Matplotlib` package (we have provided the necessary starter code for visualization). An example is shown here: \n",
    "\n",
    "\n",
    "|![alt](images/q3a.png) |![alt](images/q3b.png)|\n",
    "|-|-|\n",
    "|![alt](images/q3b.png) |![alt](images/q3c.png)|\n",
    "|-|-|\n",
    "\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: Take a few screenshots of the 3D visualization\n",
    "so that the outline of the temple is clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9bfb9cfbd2dcb325127469c72902ee9",
     "grade": false,
     "grade_id": "cell-640b94de9f802a27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute3D_pts(pts1, intrinsics, F, im1, im2):\n",
    "    '''\n",
    "    Q2.4: Finding the 3D position of given points based on epipolar correspondence and triangulation\n",
    "        Input:  pts1, chosen points from im1\n",
    "                intrinsics, the intrinsics dictionary for calling epipolarCorrespondence\n",
    "                F, the fundamental matrix\n",
    "                im1, the first image\n",
    "                im2, the second image\n",
    "        Output: P (Nx3) the recovered 3D points\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) Use epipolarCorrespondence to find the corresponding point for [x1 y1] (find [x2, y2])\n",
    "    (2) Now you have a set of corresponding points [x1, y1] and [x2, y2], you can compute the M2\n",
    "        matrix and use triangulate to find the 3D points. \n",
    "    (3) Use the function findM2 to find the 3D points P (do not recalculate fundamental matrices)\n",
    "    (4) As a reference, our solution's bet error is around ~2000 on the 3D points. \n",
    "    '''\n",
    "    x1s_temple, y1s_temple = pts1[:, 0], pts1[:, 1]\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    x2s_temple, y2s_temple = [], []\n",
    "    for (x1,y1) in list(zip(x1s_temple, y1s_temple)):\n",
    "\n",
    "        x2, y2 = epipolarCorrespondence(im1, im2, F, x1, y1)\n",
    "        x2s_temple.append(x2)\n",
    "        y2s_temple.append(y2)\n",
    "\n",
    "    pts2 = np.array(list(zip(x2s_temple, y2s_temple)))\n",
    "    M2, C2, P = find_M2(F, pts1, pts2, intrinsics)\n",
    "    # raise NotImplementedError()\n",
    "    return P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab4441f730db26b94de7e387c5f836c2",
     "grade": false,
     "grade_id": "cell-0f4232aad2b21f9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000107\n",
      "         Iterations: 8\n",
      "         Function evaluations: 894\n",
      "[[    0.     -1525.9       78.13       0.    ]\n",
      " [ 1520.4        0.      -111.68       0.    ]\n",
      " [  -27.4485 -1508.3883  -245.614   1532.9965]\n",
      " [-1519.9694    14.8087   121.2607   -48.8178]]\n",
      "[[    0.     -1525.9       78.13       0.    ]\n",
      " [ 1520.4        0.      -111.68       0.    ]\n",
      " [  -27.4485 -1508.3883  -245.614  -1532.9965]\n",
      " [-1519.9694    14.8087   121.2607    48.8178]]\n",
      "[[    0.     -1525.9       78.13       0.    ]\n",
      " [ 1520.4        0.      -111.68       0.    ]\n",
      " [   51.7203 -1496.056   -308.9604  1532.9965]\n",
      " [ 1519.1965    80.8669  -103.6004   -48.8178]]\n",
      "[[    0.     -1525.9       78.13       0.    ]\n",
      " [ 1520.4        0.      -111.68       0.    ]\n",
      " [   51.7203 -1496.056   -308.9604 -1532.9965]\n",
      " [ 1519.1965    80.8669  -103.6004    48.8178]]\n",
      "Best Error 530.871781133902\n"
     ]
    }
   ],
   "source": [
    "# Visualization:\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "templeCoords = np.load(\"data/templeCoords.npz\")\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "\n",
    "pts1 = np.hstack([templeCoords[\"x1\"], templeCoords[\"y1\"]])\n",
    "P = compute3D_pts(pts1, intrinsics, F, im1, im2)\n",
    "\n",
    "# plot_3D(P) ## uncomment to visualize, comment out before submitting to gradescope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_3D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-53059fb55b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_3D' is not defined"
     ]
    }
   ],
   "source": [
    "plot_3D(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aab0c030a892753ba59e210b4f193d36",
     "grade": true,
     "grade_id": "q2_4_a",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.5 Extra Credits: More 3D Visualization (10pts writeup) \n",
    "\n",
    "Similar to the Q2.4 visualization of the Temple image, show the 3D reconstruction of any other object using your own images. Feel free to use the images and camera parameters from the [Middlebury multiview dataset](http://vision.middlebury.edu/mview/data/) or other public datasets. Please restrict to only using 2 images and atleast 10 correspondences in both the images.\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: \n",
    "- Show the two images of the object from different views.\n",
    "- Visualize the 2D correspondences on both the images.\n",
    "- Take a few screenshots of the 3D visualization of the reconstruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('cvb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "368.111px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "c21fd19af84997c7324eb40f3f35b9c516eb0e316e912022307cacada437db6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
